{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.playback import play\n",
    "import IPython.display as ipd\n",
    "\n",
    "import os\n",
    "from pydub import AudioSegment, silence, effects\n",
    "import librosa\n",
    "import uuid\n",
    "from unidecode import unidecode\n",
    "import json\n",
    "import numpy as np\n",
    "import io\n",
    "import scipy.io.wavfile\n",
    "import array\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment, effects, silence\n",
    "import io\n",
    "import scipy.io.wavfile\n",
    "import array\n",
    "\n",
    "\n",
    "def remove_silence(audio_segment):\n",
    "    silence_list = silence.detect_silence()\n",
    "    \n",
    "\n",
    "def normalization_pipeline(audio_segment, pipeline=None):\n",
    "    \n",
    "    # assert kind is not none and raise custom message if not 'pydub' or 'jukebox'\n",
    "    \n",
    "    assert pipeline is not None, \"You must declare the normalization pipeline.\"\n",
    "    \n",
    "    if pipeline == 'pydub':\n",
    "        return effects.normalize(audio_segment)\n",
    "    \n",
    "    elif pipeline == 'jukebox':\n",
    "        # ONLY SUPPORTS MONO\n",
    "        array_segment = normalize_unit(audio_segment.get_array_of_samples())        \n",
    "        new_segment = audio_segment._spawn(array_segment)\n",
    "        return new_segment\n",
    "\n",
    "def normalize_unit(y):\n",
    "    # ONLY SUPPORTS MONO\n",
    "    norm_factor = np.abs(y).max()\n",
    "    if norm_factor > 0:\n",
    "        y /= norm_factor\n",
    "    return y\n",
    "\n",
    "\n",
    "def audiosegment_to_ndarray_32(audio_segment):\n",
    "    # ONLY SUPPORTS MONO\n",
    "    # np_segment = np.array(audio_segment.get_array_of_samples()).astype(np.float32)\n",
    "    # np_segment = np_segment / (1 << 8*2 - 1)  # normalization. AudioSegment use int16, so the max value is  `1 << 8*2 - 1`.\n",
    "    # return np_segment\n",
    "    channel_sounds = audio_segment.split_to_mono()\n",
    "    samples = [s.get_array_of_samples() for s in channel_sounds]\n",
    "\n",
    "    fp_arr = np.array(samples).T.astype(np.float32)\n",
    "    fp_arr /= np.iinfo(samples[0].typecode).max\n",
    "    return fp_arr\n",
    "\n",
    "\n",
    "def ndarray32_to_audiosegment(fp_arr,frame_rate):\n",
    "    wav_io = io.BytesIO()\n",
    "    scipy.io.wavfile.write(wav_io, 16000, fp_arr)\n",
    "    wav_io.seek(0)\n",
    "    sound = AudioSegment.from_wav(wav_io)\n",
    "    return sound\n",
    "    \n",
    "\n",
    "def remove_silence(audio_segment):\n",
    "    silence_list = silence.detect_silence()\n",
    "    \n",
    "def denoise():\n",
    "    pass\n",
    "\n",
    "def super_resolution():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_metadata(audio, filename):\n",
    "    \"\"\"\n",
    "    Generate the audio metadata for the given audio.\n",
    "\n",
    "    Parameters:\n",
    "        audio (AudioSegment): The audio segment for which to retrieve the metadata.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the audio metadata with the following keys:\n",
    "            - sample_rate (int): The sample rate of the audio.\n",
    "            - channels (int): The number of audio channels.\n",
    "            - bytes_per_sample (int): The number of bytes per audio sample. A value of 1 indicates 8 bit, and a value of 2 indicates 16 bit.\n",
    "    \"\"\"\n",
    "    meta =  {\n",
    "        \"sample_rate\": audio.frame_rate,\n",
    "        \"channels\": audio.channels, \n",
    "        \"bytes_per_sample\":audio.sample_width, # 1 means 8 bit, 2 means 16 bit   \n",
    "        \"filename\":filename\n",
    "    }\n",
    "\n",
    "    return meta\n",
    "        \n",
    "def segment_audio(\n",
    "        file_path, out_dir, segment_length_s=10, target_sr=32000, n_channels=1,\n",
    "        cutoff='pad', overlap=0.0, normalize_loudness=True, normalize_amplitude=True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Segment an audio file into smaller segments of a specified length.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the audio file.\n",
    "        out_dir (str): The directory where the segmented audio files will be saved.\n",
    "        segment_length_s (float, optional): The length of each segment in seconds. Defaults to 10.\n",
    "        target_sr (int, optional): The target sample rate of the audio. Defaults to 32000.\n",
    "        n_channels (int, optional): The number of channels in the audio. Defaults to 1.\n",
    "        cutoff (str, optional): The method to handle segments that are shorter than segment_length_s. \n",
    "                               Can be 'pad', 'leave', or 'crop'. Defaults to 'pad'.\n",
    "        overlap (float, optional): The overlap between consecutive segments as a fraction of segment_length_s. \n",
    "                                   Defaults to 0.0.\n",
    "        normalize (bool, optional): Whether to normalize the audio. Defaults to False.\n",
    "        denoise (bool, optional): Whether to denoise the audio. Defaults to False.\n",
    "        desilence (bool, optional): Whether to remove silence from the audio. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Get file name without extension for caption\n",
    "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    file_name = unidecode(file_name.lower())\n",
    "    \n",
    "    # load audio\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    \n",
    "    # resample\n",
    "    if target_sr is not None:\n",
    "        audio = audio.set_frame_rate(target_sr) # resample to target_sr\n",
    "    \n",
    "    # force mono/stereo          \n",
    "    if n_channels is not None:\n",
    "        audio = audio.set_channels(n_channels) # convert to mono\n",
    "    \n",
    "    # normalize loudness\n",
    "    if normalize_loudness:\n",
    "        audio = effects.normalize(audio)\n",
    "    \n",
    "    # Audio info dict\n",
    "    audio_metadata = get_audio_metadata(audio, file_name)\n",
    "    \n",
    "    # turn into np array \n",
    "    np_audio = audiosegment_to_ndarray_32(audio)\n",
    "    \n",
    "    # normalize between -1 and 1\n",
    "    if normalize_amplitude:\n",
    "        np_audio = normalize_unit(np_audio)\n",
    "\n",
    "    # segment into segment_length_s samples\n",
    "    segment_length_samples = segment_length_s * audio.frame_rate\n",
    "    step = int((1-overlap)*segment_length_samples)\n",
    "    for i in range(0, len(np_audio), step):\n",
    "        # create segment\n",
    "        start_time = i \n",
    "        end_time = i + segment_length_samples\n",
    "        segment = np_audio[start_time:end_time][:,0]\n",
    "        \n",
    "        # pad or crop end-of-file samples\n",
    "        if end_time > len(audio):\n",
    "            if cutoff=='pad': # pad with silence (0 amplitude)\n",
    "                # if len(segment) < 0.5*segment_length_samples: # pad at most 50% of the signal\n",
    "                #     break\n",
    "                pad_len = segment_length_samples - len(segment)\n",
    "        \n",
    "                # Pad with 0s\n",
    "                pad = np.zeros(pad_len)\n",
    "                segment = np.concatenate((segment,pad), axis=0)\n",
    "            \n",
    "            elif cutoff=='leave': # save sample smaller than segment_length_s\n",
    "                segment = audio[start_time:len(audio)] \n",
    "            \n",
    "            elif cutoff=='crop': # discard smaller sample\n",
    "                break\n",
    "            \n",
    "        save_sample_meta(audio_metadata, segment, out_dir)\n",
    "\n",
    "def save_sample_meta(audio_meta, segment, out_dir):\n",
    "    \"\"\"\n",
    "    Save the audio segment and its metadata to the specified output directory.\n",
    "\n",
    "    Args:\n",
    "        audio_meta (dict): Metadata for the audio segment.\n",
    "        segment (AudioSegment): Audio segment to be saved.\n",
    "        out_dir (str): Output directory where the segment and metadata will be saved.\n",
    "    \"\"\"\n",
    "    # declare metadata and sample dirs\n",
    "    sample_dir = os.path.join(out_dir, 'samples')\n",
    "    meta_dir = os.path.join(out_dir, 'metadata')\n",
    "    \n",
    "    # create sample and metadata directories if they don't exist\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "    os.makedirs(meta_dir, exist_ok=True)\n",
    "    \n",
    "    sample_name = str(uuid.uuid4())\n",
    "    seg_path = os.path.join(sample_dir, f'{sample_name}.wav')\n",
    "    meta_path = os.path.join(meta_dir, f'{sample_name}.json')\n",
    "    \n",
    "    # create a copy of audio_meta dictionary to add segment specific information\n",
    "    segment_meta_dict = audio_meta.copy()\n",
    "    \n",
    "    # Save the segment as a WAV file\n",
    "    scipy.io.wavfile.write(seg_path, segment_meta_dict[\"sample_rate\"], segment)\n",
    "    \n",
    "    # Save the metadata as a JSON file\n",
    "    with open(meta_path, 'w', encoding='utf8') as fp:\n",
    "        json.dump(segment_meta_dict, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/home/cvillela/Downloads/dvorak_dreams_audios/dvorak_dreams_mst_ch1.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.2044684886932373 seconds\n"
     ]
    }
   ],
   "source": [
    "outdir = \"./test_segs_pydub/\"\n",
    "start = time()\n",
    "segment_audio(\n",
    "        filepath, outdir, segment_length_s=10, target_sr=32000, n_channels=1,\n",
    "        cutoff='pad', overlap=0.0, normalize_loudness=True, normalize_amplitude=True\n",
    "    )\n",
    "end = time()\n",
    "print(f'Took {end-start} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ras_audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
